{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:05:50.740650Z",
     "start_time": "2024-12-01T10:05:50.738175Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a838bf34a72cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:05:53.039004Z",
     "start_time": "2024-12-01T10:05:53.035657Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),  # Augmentation\n",
    "    transforms.RandomRotation(15),  # Augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d48664c42c4d95e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:05:56.010310Z",
     "start_time": "2024-12-01T10:05:55.981424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths to dataset folders\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform_train)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform_val)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Debugging Outputs\n",
    "print(f\"Train Dataset Size: {len(train_dataset)}\")\n",
    "print(f\"Test Dataset Size: {len(test_dataset)}\")\n",
    "print(f\"Train Loader Size: {len(train_loader)}\")\n",
    "print(f\"Test Loader Size: {len(test_loader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2f7536e6efeef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:46:38.241827Z",
     "start_time": "2024-12-01T10:46:37.708044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pretrained EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "# Modify the final layer for 3 classes (NORMAL, PNEUMONIA, COVID)\n",
    "num_classes = 3\n",
    "model._fc = nn.Linear(model._fc.in_features, num_classes)\n",
    "\n",
    "# Send model to device (GPU/CPU)\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"mps\" if torch.backends.mps.is_available() else\n",
    "    \"cpu\"\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Debugging Outputs\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS Available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946dcb360b949fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:46:43.795285Z",
     "start_time": "2024-12-01T10:46:43.753858Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44475883312ce16c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:46:44.986219Z",
     "start_time": "2024-12-01T10:46:44.983606Z"
    }
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540f1e5560587dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T10:47:23.694046Z",
     "start_time": "2024-12-01T10:46:47.659864Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += torch.sum(preds == labels).item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_accuracy = 100.0 * train_correct / total_train\n",
    "    train_losses.append(train_loss / len(train_loader))  # Append training loss\n",
    "    train_accuracies.append(train_accuracy)  # Append training accuracy\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels).item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100.0 * val_correct / total_val\n",
    "    val_losses.append(val_loss / len(test_loader))  # Append validation loss\n",
    "    val_accuracies.append(val_accuracy)  # Append validation accuracy\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss / len(test_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54602a28406262e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:08:04.740194Z",
     "start_time": "2024-11-30T17:08:04.491305Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f9a97e96cc6702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:09:13.013326Z",
     "start_time": "2024-11-30T17:09:12.902939Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'efficientnet_chest_xray_b7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6e45ed4a739a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:09:17.346002Z",
     "start_time": "2024-11-30T17:09:17.113322Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('efficientnet_chest_xray_b7.pth', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd088d05529ebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:09:42.557606Z",
     "start_time": "2024-11-30T17:09:27.026104Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5909e56567cd1",
   "metadata": {},
   "source": [
    "#### Predicting on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee29490d29d1ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:10:11.159462Z",
     "start_time": "2024-11-30T17:10:11.084924Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load class names dynamically\n",
    "train_dataset = datasets.ImageFolder(root='data/train')\n",
    "class_names = train_dataset.classes  # Dynamically load class names\n",
    "\n",
    "# Updated transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Ensure 3 channels for grayscale images\n",
    "    transforms.Resize((224, 224)),  # Resize to EfficientNet input size\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize for ImageNet weights\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load and preprocess image\n",
    "# img = Image.open('data/test/COVID19/COVID19(464).jpg')\n",
    "# img = Image.open('data/test/NORMAL/NORMAL(1266).jpg')\n",
    "img = Image.open('data/test/PNEUMONIA/PNEUMONIA(3418).jpg')\n",
    "img = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    img = img.to(device)\n",
    "    outputs = model(img)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predicted_class = class_names[predicted.item()]  # Get class name\n",
    "    print(f'Predicted Class: {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f346c218314e245b",
   "metadata": {},
   "source": [
    "#### Train images:\n",
    "- COVID19: 460 images\n",
    "- NORMAL: 1266 images\n",
    "- PNEUMONIA: 3418 images\n",
    "\n",
    "#### Test images:\n",
    "- COVID19: 116 images\n",
    "- NORMAL: 317 images\n",
    "- PNEUMONIA: 855 images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf15f9d36b9c5fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:11:33.908995Z",
     "start_time": "2024-11-30T17:10:17.344140Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to compute confusion matrix for a given DataLoader\n",
    "def compute_confusion_matrix(loader, model, device):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())  # Collect all predictions\n",
    "            all_labels.extend(labels.cpu().numpy())  # Collect all true labels\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return cm\n",
    "\n",
    "\n",
    "# Compute confusion matrices\n",
    "train_cm = compute_confusion_matrix(train_loader, model, device)\n",
    "test_cm = compute_confusion_matrix(test_loader, model, device)\n",
    "\n",
    "# Plot Training Confusion Matrix\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=train_cm, display_labels=class_names)\n",
    "disp_train.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Training Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot Testing Confusion Matrix\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=test_cm, display_labels=class_names)\n",
    "disp_test.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Testing Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69958cdacc5bf0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T09:49:36.938323Z",
     "start_time": "2024-12-01T09:49:21.632363Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Print metrics per class\n",
    "for i, cls in enumerate(class_names):\n",
    "    print(f\"Class: {cls}\")\n",
    "    print(f\"  Precision: {precision[i]:.2f}\")\n",
    "    print(f\"  Recall: {recall[i]:.2f}\")\n",
    "    print(f\"  F1 Score: {f1[i]:.2f}\")\n",
    "    print(f\"  Support: {support[i]}\")\n",
    "\n",
    "# Overall metrics\n",
    "precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "print(f\"Macro F1 Score: {f1_macro:.2f}\")\n",
    "\n",
    "precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7290ea803c63e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
